//package antlr
//
//import (
//  "strconv"
//  "strings"
//)
//
//pub struct TokenSourceCharStreamPair {
//  token_source: TokenSource
//  char_stream:  CharStream
//}
//
//// A token has properties: text, type, line, character position in the line
//// (so we can ignore tabs), token channel, index, and source from which
//// we obtained this token.
//
//pub trait Token {
//  GetSource() *TokenSourceCharStreamPair
//  GetTokenType() i32
//  GetChannel() i32
//  GetStart() i32
//  GetStop() i32
//  GetLine() i32
//  GetColumn() i32
//
//  GetText() &str
//  SetText(s &str)
//
//  GetTokenIndex() i32
//  SetTokenIndex(v i32)
//
//  GetTokenSource() TokenSource
//  GetInputStream() CharStream
//}
//
//pub struct BaseToken {
//  source:     *TokenSourceCharStreamPair
//  token_type  i32    // token type of the token
//  channel    i32    // The parser ignores everything not on DEFAULT_CHANNEL
//  start      i32    // optional return -1 if not implemented.
//  stop       i32    // optional return -1 if not implemented.
//  token_index i32    // from 0..n-1 of the token object in the input stream
//  line       i32    // line=1..n of the 1st character
//  column     i32    // beginning of the line at which it occurs, 0..n-1
//  text       &str // text of the token.
//  read_only:   bool
//}
//
//const (
//  TokenInvalidType = 0
//
//  // During lookahead operations, this "token" signifies we hit rule end ATN state
//  // and did not follow it despite needing to.
//  TokenEpsilon = -2
//
//  TokenMinUserTokenType = 1
//
//  TokenEOF = -1
//
//  // All tokens go to the parser (unless Skip() is called in that rule)
//  // on a particular "channel". The parser tunes to a particular channel
//  // so that whitespace etc... can go to the parser on a "hidden" channel.
//
//  TokenDefaultChannel = 0
//
//  // Anything on different channel than DEFAULT_CHANNEL is not parsed
//  // by parser.
//
//  TokenHiddenChannel = 1
//)
//
//pub fn GetChannel(&self, ) -> i32 {
//  return b.channel
//}
//
//pub fn GetStart(&self, ) -> i32 {
//  return b.start
//}
//
//pub fn GetStop(&self, ) -> i32 {
//  return b.stop
//}
//
//pub fn GetLine(&self, ) -> i32 {
//  return b.line
//}
//
//pub fn GetColumn(&self, ) -> i32 {
//  return b.column
//}
//
//pub fn GetTokenType(&self, ) -> i32 {
//  return b.token_type
//}
//
//pub fn GetSource(&self, ) -> *TokenSourceCharStreamPair {
//  return b.source
//}
//
//pub fn GetTokenIndex(&self, ) -> i32 {
//  return b.token_index
//}
//
//pub fn SetTokenIndex(&self, v: i32) {
//  b.token_index = v
//}
//
//pub fn GetTokenSource(&self, ) -> TokenSource {
//  return b.source.token_source
//}
//
//pub fn GetInputStream(&self, ) -> CharStream {
//  return b.source.char_stream
//}
//
//pub struct CommonToken {
//  *BaseToken
//}
//
//impl CommonToken {ยง//  pub fn new(&self, source *TokenSourceCharStreamPair, token_type, channel,: start, stop: i32) -> *CommonToken {
//
//  let t = new(CommonToken);
//
//  t.BaseToken = new(BaseToken)
//
//  t.source = source
//  t.token_type = token_type
//  t.channel = channel
//  t.start = start
//  t.stop = stop
//  t.token_index = -1
//  if t.source.token_source != nil {
//    t.line = source.token_source.GetLine()
//    t.column = source.token_source.GetCharPositionInLine()
//  } else {
//    t.column = -1
//  }
//  return t
//}
//
//// An empty {@link Pair} which is used as the default value of
//// {@link //source} for tokens that do not have a source.
//
////CommonToken.EMPTY_SOURCE = [ nil, nil ]
//
//// Constructs a New{@link CommonToken} as a copy of another {@link Token}.
////
//// <p>
//// If {@code old_token} is also a {@link CommonToken} instance, the newly
//// constructed token will share a reference to the {@link //text} field and
//// the {@link Pair} stored in {@link //source}. Otherwise, {@link //text} will
//// be assigned the result of calling {@link //GetText}, and {@link //source}
//// will be constructed from the result of {@link Token//GetTokenSource} and
//// {@link Token//GetInputStream}.</p>
////
//// @param old_token The token to copy.
////
//pub fn clone(&self, ) -> *CommonToken {
//  let t = NewCommonToken(c.source, c.token_type, c.channel, c.start, c.stop);
//  t.token_index = c.GetTokenIndex()
//  t.line = c.GetLine()
//  t.column = c.GetColumn()
//  t.text = c.GetText()
//  return t
//}
//
//pub fn GetText(&self, ) -> &str {
//  if c.text != "" {
//    return c.text
//  }
//  let input = c.GetInputStream();
//  if input == nil {
//    return ""
//  }
//  let n = input.Size();
//  if c.start < n && c.stop < n {
//    return input.GetTextFromInterval(NewInterval(c.start, c.stop))
//  }
//  return "<EOF>"
//}
//
//pub fn SetText(&self, text: &str) {
//  c.text = text
//}
//
//pub fn String(&self, ) -> &str {
//  let txt = c.GetText();
//  if txt != "" {
//    txt = &strs.Replace(txt, "\n", "\\n", -1)
//    txt = &strs.Replace(txt, "\r", "\\r", -1)
//    txt = &strs.Replace(txt, "\t", "\\t", -1)
//  } else {
//    txt = "<no text>"
//  }
//
//  var ch &str
//  if c.channel > 0 {
//    ch = ",channel=" + strconv.Itoa(c.channel)
//  } else {
//    ch = ""
//  }
//
//  return "[@" + strconv.Itoa(c.token_index) + "," + strconv.Itoa(c.start) + ":" + strconv.Itoa(c.stop) + "='" +
//    txt + "',<" + strconv.Itoa(c.token_type) + ">" +
//    ch + "," + strconv.Itoa(c.line) + ":" + strconv.Itoa(c.column) + "]"
//}
