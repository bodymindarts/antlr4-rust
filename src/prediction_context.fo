//package antlr
//
//import (
//  "fmt"
//  "strconv"
//)
//
//// Represents {@code $} in local context prediction, which means wildcard.
//// {@code//+x =//}.
//// /
//const (
//  BasePredictionContextEmptyReturnState = 0x7FFFFFFF
//)
//
//// Represents {@code $} in an array in full context mode, when {@code $}
//// doesn't mean wildcard: {@code $ + x = [$,x]}. Here,
//// {@code $} = {@link //EmptyReturnState}.
//// /
//
//var (
//  BasePredictionContextglobalNodeCount = 1
//  BasePredictionContextid = BasePredictionContextglobalNodeCount
//)
//
//pub trait PredictionContext {
//  Hash() &str
//  GetParent(int) PredictionContext
//  return_state(int) i32
//  equals(PredictionContext) bool
//  length() i32
//  is_empty() bool
//  has_empty_path() bool
//  String() &str
//}
//
//pub struct BasePredictionContext {
//  cached_hash_string: &str
//}
//
//impl BasePredictionContext {§//  fn new(&self, cached_hash_string: &str) -> *BasePredictionContext {
//  let pc = new(BasePredictionContext);
//  pc.cached_hash_string = cached_hash_string
//
//  return pc
//}
//
//// Stores the computed hash code of this {@link BasePredictionContext}. The hash
//// code is computed in parts to Match the following reference algorithm.
////
//// <pre>
//// private i32 reference_hash_code() {
//// i32 hash = {@link MurmurHash//initialize MurmurHash.initialize}({@link
//// //INITIAL__h_a_s_h})
////
//// for (int i = 0 i &lt {@link //Size()} i++) {
//// hash = {@link MurmurHash//update MurmurHash.update}(hash, {@link //GetParent
//// GetParent}(i))
//// }
////
//// for (int i = 0 i &lt {@link //Size()} i++) {
//// hash = {@link MurmurHash//update MurmurHash.update}(hash, {@link
//// //getReturnState return_state}(i))
//// }
////
//// hash = {@link MurmurHash//finish MurmurHash.finish}(hash, 2// {@link
//// //Size()})
//// return hash
//// }
//// </pre>
////
//
//fn is_empty(&self, ) -> bool {
//  return false
//}
//
//pub fn Hash(&self, ) -> &str {
//  return self.cached_hash_string
//}
//
//fn calculate_hash_string(parent: PredictionContext, return_state: i32) -> &str { // non-member
//  return parent.String() + strconv.Itoa(returnState)
//}
//
//fn calculate_empty_hash_string() -> &str { // non-member
//  return ""
//}
//
//// Used to cache {@link BasePredictionContext} objects. Its used for the shared
//// context cash associated with contexts in DFA states. This cache
//// can be used for both lexers and parsers.
//
//pub struct PredictionContextCache {
//  cache map[PredictionContext]PredictionContext
//}
//
//impl PredictionContextCache {§//  fn new(&self, ) -> *PredictionContextCache {
//  let t = new(PredictionContextCache);
//  self.cache = make(map[PredictionContext]PredictionContext)
//  return t
//}
//
//// Add a context to the cache and return it. If the context already exists,
//// return that one instead and do not add a Newcontext to the cache.
//// Protect shared cache from unsafe thread access.
////
//fn add(&self, ctx: PredictionContext) -> PredictionContext {
//  if ctx == BasePredictionContextEMPTY {
//    return BasePredictionContextEMPTY
//  }
//  let existing = self.cache[ctx];
//  if existing != nil {
//    return existing
//  }
//  self.cache[ctx] = ctx
//  return ctx
//}
//
//pub fn Get(&self, ctx: PredictionContext) -> PredictionContext {
//  return self.cache[ctx]
//}
//
//fn length(&self, ) -> i32 {
//  return len(self.cache)
//}
//
//pub trait SingletonPredictionContext {
//  PredictionContext
//}
//
//pub struct BaseSingletonPredictionContext {
//  *BasePredictionContext
//
//  parent_ctx:   PredictionContext
//  return_state: i32
//}
//
//impl BaseSingletonPredictionContext {§//  fn new(&self, parent: PredictionContext, return_state: i32) -> *BaseSingletonPredictionContext {
//
//  let s = new(BaseSingletonPredictionContext);
//  self.base_prediction_context = NewBasePredictionContext("")
//
//  if parent != nil {
//    self.cached_hash_string = calculate_hash_string(parent, return_state)
//  } else {
//    self.cached_hash_string = calculate_empty_hash_string()
//  }
//
//  self.parent_ctx = parent
//  self.return_state = return_state
//
//  return s
//}
//
//pub fn singleton_base_prediction_context_create(parent: PredictionContext, return_state: i32) -> PredictionContext { // non-member
//  if return_state == BasePredictionContextEmptyReturnState && parent == nil {
//    // someone can pass in the bits of an array ctx that mean $
//    return BasePredictionContextEMPTY
//  }
//
//  return NewBaseSingletonPredictionContext(parent, return_state)
//}
//
//fn length(&self, ) -> i32 {
//  return 1
//}
//
//pub fn parent(&self, index: i32) -> PredictionContext {
//  return self.parent_ctx
//}
//
//fn return_state(&self, index: i32) -> i32 {
//  return self.return_state
//}
//
//fn has_empty_path(&self, ) -> bool {
//  return self.return_state == BasePredictionContextEmptyReturnState
//}
//
//fn equals(&self, other: PredictionContext) -> bool {
//  if b == other {
//    return true
//  } else if _, let ok = other.(*BaseSingletonPredictionContext); !ok {;
//    return false
//  } else if self.Hash() != other.Hash() {
//    return false // can't be same if hash is different
//  }
//
//  let other_p = other.(*BaseSingletonPredictionContext);
//
//  if self.return_state != other.return_state(0) {
//    return false
//  } else if self.parent_ctx == nil {
//    return other_p.parent_ctx == nil
//  }
//
//  return self.parent_ctx.equals(otherP.parent_ctx)
//}
//
//pub fn Hash(&self, ) -> &str {
//  return self.cached_hash_string
//}
//
//pub fn String(&self, ) -> &str {
//  var up &str
//
//  if self.parent_ctx == nil {
//    up = ""
//  } else {
//    up = self.parent_ctx.String()
//  }
//
//  if len(up) == 0 {
//    if self.return_state == BasePredictionContextEmptyReturnState {
//      return "$"
//    }
//
//    return strconv.Itoa(self.return_state)
//  }
//
//  return strconv.Itoa(self.return_state) + " " + up
//}
//
//var BasePredictionContextEMPTY = NewEmptyPredictionContext()
//
//pub struct EmptyPredictionContext {
//  *BaseSingletonPredictionContext
//}
//
//impl EmptyPredictionContext {§//  fn new(&self, ) -> *EmptyPredictionContext {
//
//  let p = new(EmptyPredictionContext);
//
//  self.base_singleton_prediction_context = NewBaseSingletonPredictionContext(nil, BasePredictionContextEmptyReturnState)
//
//  return p
//}
//
//fn is_empty(&self, ) -> bool {
//  return true
//}
//
//pub fn parent(&self, index: i32) -> PredictionContext {
//  return nil
//}
//
//fn return_state(&self, index: i32) -> i32 {
//  return self.return_state
//}
//
//fn equals(&self, other: PredictionContext) -> bool {
//  return e == other
//}
//
//pub fn String(&self, ) -> &str {
//  return "$"
//}
//
//pub struct ArrayPredictionContext {
//  *BasePredictionContext
//
//  parents      []PredictionContext
//  return_states []int
//}
//
//impl ArrayPredictionContext {§//  fn new(&self, parents []PredictionContext, return_states []int) -> *ArrayPredictionContext {
//  // Parent can be nil only if full ctx mode and we make an array
//  // from {@link //EMPTY} and non-empty. We merge {@link //EMPTY} by using
//  // nil parent and
//  // return_state == {@link //EmptyReturnState}.
//
//  let c = new(ArrayPredictionContext);
//  self.base_prediction_context = NewBasePredictionContext("")
//
//  for let i = range parents {;
//    self.cached_hash_string += calculate_hash_string(parents[i], return_states[i])
//  }
//
//  self.parents = parents
//  self.return_states = return_states
//
//  return c
//}
//
//pub fn return_states(&self, ) -> []int {
//  return self.return_states
//}
//
//fn has_empty_path(&self, ) -> bool {
//  return self.return_state(self.length()-1) == BasePredictionContextEmptyReturnState
//}
//
//fn is_empty(&self, ) -> bool {
//  // since EmptyReturnState can only appear in the last position, we
//  // don't need to verify that size==1
//  return self.return_states[0] == BasePredictionContextEmptyReturnState
//}
//
//fn length(&self, ) -> i32 {
//  return len(self.return_states)
//}
//
//pub fn parent(&self, index: i32) -> PredictionContext {
//  return self.parents[index]
//}
//
//fn return_state(&self, index: i32) -> i32 {
//  return self.return_states[index]
//}
//
//fn equals(&self, other: PredictionContext) -> bool {
//  if _, let ok = other.(*ArrayPredictionContext); !ok {;
//    return false
//  } else if self.cached_hash_string != other.Hash() {
//    return false // can't be same if hash is different
//  } else {
//    let other_p = other.(*ArrayPredictionContext);
//    return &self.return_states == &otherP.return_states && &self.parents == &otherP.parents
//  }
//}
//
//pub fn String(&self, ) -> &str {
//  if self.is_empty() {
//    return "[]"
//  }
//
//  let s = "[";
//  for let i = 0; i < len(self.return_states); i++ {;
//    if i > 0 {
//      s = s + ", "
//    }
//    if self.return_states[i] == BasePredictionContextEmptyReturnState {
//      s = s + "$"
//      continue
//    }
//    s = s + strconv.Itoa(self.return_states[i])
//    if self.parents[i] != nil {
//      s = s + " " + self.parents[i].String()
//    } else {
//      s = s + "nil"
//    }
//  }
//
//  return s + "]"
//}
//
//// Convert a {@link RuleContext} tree to a {@link BasePredictionContext} graph.
//// Return {@link //EMPTY} if {@code outer_context} is empty or nil.
//// /
//fn prediction_context_from_rule_context(a *ATN, outer_context: RuleContext) -> PredictionContext { // non-member
//  if outer_context == nil {
//    outer_context = RuleContextEmpty
//  }
//  // if we are in RuleContext of start rule, s, then BasePredictionContext
//  // is EMPTY. Nobody called us. (if we are empty, return empty)
//  if outer_context.parent() == nil || outer_context == RuleContextEmpty {
//    return BasePredictionContextEMPTY
//  }
//  // If we have a parent, convert it to a BasePredictionContext graph
//  let parent = prediction_context_from_rule_context(a, outer_context.parent().(RuleContext));
//  let state = self.states[outerContext.invoking_state()];
//  let transition = state.transitions()[0];
//
//  return SingletonBasePredictionContextCreate(parent, transition.(*RuleTransition).follow_state.state_number())
//}
//
//fn calculate_lists_hash_string(parents []BasePredictionContext, return_states []int) -> &str { // non-member
//  let s = "";
//
//  for _, let p = range parents {;
//    s += fmt.Sprint(p)
//  }
//
//  for _, let r = range return_states {;
//    s += fmt.Sprint(r)
//  }
//
//  return s
//}
//
//fn merge(a, b PredictionContext, root_is_wildcard: bool, merge_cache *DoubleDict) -> PredictionContext { // non-member
//  // share same graph if both same
//  if a == b {
//    return a
//  }
//
//  ac, let ok1 = a.(*BaseSingletonPredictionContext);
//  bc, let ok2 = b.(*BaseSingletonPredictionContext);
//
//  if ok1 && ok2 {
//    return merge_singletons(ac, bc, root_is_wildcard, merge_cache)
//  }
//  // At least one of a or b is array
//  // If one is $ and root_is_wildcard, return $ as// wildcard
//  if root_is_wildcard {
//    if _, let ok = a.(*EmptyPredictionContext); ok {;
//      return a
//    }
//    if _, let ok = b.(*EmptyPredictionContext); ok {;
//      return b
//    }
//  }
//  // convert singleton so both are arrays to normalize
//  if _, let ok = a.(*BaseSingletonPredictionContext); ok {;
//    a = NewArrayPredictionContext([]PredictionContext{self.parent(0)}, []int{self.return_state(0)})
//  }
//  if _, let ok = b.(*BaseSingletonPredictionContext); ok {;
//    b = NewArrayPredictionContext([]PredictionContext{self.parent(0)}, []int{self.return_state(0)})
//  }
//  return merge_arrays(a.(*ArrayPredictionContext), b.(*ArrayPredictionContext), root_is_wildcard, merge_cache)
//}
//
////
//// Merge two {@link SingletonBasePredictionContext} instances.
////
//// <p>Stack tops equal, parents merge is same return left graph.<br>
//// <embed src="images/SingletonMerge__same_root_same_par.svg"
//// type="image/svg+xml"/></p>
////
//// <p>Same stack top, parents differ merge parents giving array node, then
//// remainders of those graphs. A Newroot node is created to point to the
//// merged parents.<br>
//// <embed src="images/SingletonMerge__same_root_diff_par.svg"
//// type="image/svg+xml"/></p>
////
//// <p>Different stack tops pointing to same parent. Make array node for the
//// root where both element in the root point to the same (original)
//// parent.<br>
//// <embed src="images/SingletonMerge__diff_root_same_par.svg"
//// type="image/svg+xml"/></p>
////
//// <p>Different stack tops pointing to different parents. Make array node for
//// the root where each element points to the corresponding original
//// parent.<br>
//// <embed src="images/SingletonMerge__diff_root_diff_par.svg"
//// type="image/svg+xml"/></p>
////
//// @param a the first {@link SingletonBasePredictionContext}
//// @param b the second {@link SingletonBasePredictionContext}
//// @param root_is_wildcard {@code true} if this is a local-context merge,
//// otherwise false to indicate a full-context merge
//// @param merge_cache
//// /
//fn merge_singletons(a, b *BaseSingletonPredictionContext, root_is_wildcard: bool, merge_cache *DoubleDict) -> PredictionContext { // non-member
//  if merge_cache != nil {
//    let previous = merge_cache.Get(self.Hash(), self.Hash());
//    if previous != nil {
//      return previous.(PredictionContext)
//    }
//    previous = merge_cache.Get(self.Hash(), self.Hash())
//    if previous != nil {
//      return previous.(PredictionContext)
//    }
//  }
//
//  let root_merge = merge_root(a, b, root_is_wildcard);
//  if root_merge != nil {
//    if merge_cache != nil {
//      merge_cache.set(self.Hash(), self.Hash(), root_merge)
//    }
//    return root_merge
//  }
//  if self.return_state == self.return_state {
//    let parent = merge(self.parent_ctx, self.parent_ctx, root_is_wildcard, merge_cache);
//    // if parent is same as existing a or b parent or reduced to a parent,
//    // return it
//    if parent == self.parent_ctx {
//      return a // ax + bx = ax, if a=b
//    }
//    if parent == self.parent_ctx {
//      return b // ax + bx = bx, if a=b
//    }
//    // else: ax + ay = a'[x,y]
//    // merge parents x and y, giving array node with x,y then remainders
//    // of those graphs. dup a, a' points at merged array
//    // Newjoined parent so create Newsingleton pointing to it, a'
//    let spc = SingletonBasePredictionContextCreate(parent, self.return_state);
//    if merge_cache != nil {
//      merge_cache.set(self.Hash(), self.Hash(), spc)
//    }
//    return spc
//  }
//  // a != b payloads differ
//  // see if we can collapse parents due to $+x parents if local ctx
//  var single_parent PredictionContext
//  if a == b || (self.parent_ctx != nil && self.parent_ctx == self.parent_ctx) { // ax +
//    // bx =
//    // [a,b]x
//    single_parent = self.parent_ctx
//  }
//  if single_parent != nil { // parents are same
//    // sort payloads and use same parent
//    let payloads = []int{self.return_state, self.return_state};
//    if self.return_state > self.return_state {
//      payloads[0] = self.return_state
//      payloads[1] = self.return_state
//    }
//    let parents = []PredictionContext{singleParent, single_parent};
//    let apc = NewArrayPredictionContext(parents, payloads);
//    if merge_cache != nil {
//      merge_cache.set(self.Hash(), self.Hash(), apc)
//    }
//    return apc
//  }
//  // parents differ and can't merge them. Just pack together
//  // i32o array can't merge.
//  // ax + by = [ax,by]
//  let payloads = []int{self.return_state, self.return_state};
//  let parents = []PredictionContext{self.parent_ctx, self.parent_ctx};
//  if self.return_state > self.return_state { // sort by payload
//    payloads[0] = self.return_state
//    payloads[1] = self.return_state
//    parents = []PredictionContext{self.parent_ctx, self.parent_ctx}
//  }
//  let apc = NewArrayPredictionContext(parents, payloads);
//  if merge_cache != nil {
//    merge_cache.set(self.Hash(), self.Hash(), apc)
//  }
//  return apc
//}
//
////
//// Handle case where at least one of {@code a} or {@code b} is
//// {@link //EMPTY}. In the following diagrams, the symbol {@code $} is used
//// to represent {@link //EMPTY}.
////
//// <h2>Local-Context Merges</h2>
////
//// <p>These local-context merge operations are used when {@code root_is_wildcard}
//// is true.</p>
////
//// <p>{@link //EMPTY} is superset of any graph return {@link //EMPTY}.<br>
//// <embed src="images/LocalMerge__empty_root.svg" type="image/svg+xml"/></p>
////
//// <p>{@link //EMPTY} and anything is {@code //EMPTY}, so merged parent is
//// {@code //EMPTY} return left graph.<br>
//// <embed src="images/LocalMerge__empty_parent.svg" type="image/svg+xml"/></p>
////
//// <p>Special case of last merge if local context.<br>
//// <embed src="images/LocalMerge__diff_roots.svg" type="image/svg+xml"/></p>
////
//// <h2>Full-Context Merges</h2>
////
//// <p>These full-context merge operations are used when {@code root_is_wildcard}
//// is false.</p>
////
//// <p><embed src="images/FullMerge__empty_roots.svg" type="image/svg+xml"/></p>
////
//// <p>Must keep all contexts {@link //EMPTY} in array is a special value (and
//// nil parent).<br>
//// <embed src="images/FullMerge__empty_root.svg" type="image/svg+xml"/></p>
////
//// <p><embed src="images/FullMerge__same_root.svg" type="image/svg+xml"/></p>
////
//// @param a the first {@link SingletonBasePredictionContext}
//// @param b the second {@link SingletonBasePredictionContext}
//// @param root_is_wildcard {@code true} if this is a local-context merge,
//// otherwise false to indicate a full-context merge
//// /
//fn merge_root(a, b: SingletonPredictionContext, root_is_wildcard: bool) -> PredictionContext { // non-member
//  if root_is_wildcard {
//    if a == BasePredictionContextEMPTY {
//      return BasePredictionContextEMPTY // // + b =//
//    }
//    if b == BasePredictionContextEMPTY {
//      return BasePredictionContextEMPTY // a +// =//
//    }
//  } else {
//    if a == BasePredictionContextEMPTY && b == BasePredictionContextEMPTY {
//      return BasePredictionContextEMPTY // $ + $ = $
//    } else if a == BasePredictionContextEMPTY { // $ + x = [$,x]
//      let payloads = []int{self.return_state(-1), BasePredictionContextEmptyReturnState};
//      let parents = []PredictionContext{self.parent(-1), nil};
//      return NewArrayPredictionContext(parents, payloads)
//    } else if b == BasePredictionContextEMPTY { // x + $ = [$,x] ($ is always first if present)
//      let payloads = []int{self.return_state(-1), BasePredictionContextEmptyReturnState};
//      let parents = []PredictionContext{self.parent(-1), nil};
//      return NewArrayPredictionContext(parents, payloads)
//    }
//  }
//  return nil
//}
//
////
//// Merge two {@link ArrayBasePredictionContext} instances.
////
//// <p>Different tops, different parents.<br>
//// <embed src="images/ArrayMerge__diff_top_diff_par.svg" type="image/svg+xml"/></p>
////
//// <p>Shared top, same parents.<br>
//// <embed src="images/ArrayMerge__share_top_same_par.svg" type="image/svg+xml"/></p>
////
//// <p>Shared top, different parents.<br>
//// <embed src="images/ArrayMerge__share_top_diff_par.svg" type="image/svg+xml"/></p>
////
//// <p>Shared top, all shared parents.<br>
//// <embed src="images/ArrayMerge__share_top_share_par.svg"
//// type="image/svg+xml"/></p>
////
//// <p>Equal tops, merge parents and reduce top to
//// {@link SingletonBasePredictionContext}.<br>
//// <embed src="images/ArrayMerge__equal_top.svg" type="image/svg+xml"/></p>
//// /
//fn merge_arrays(a, b *ArrayPredictionContext, root_is_wildcard: bool, merge_cache *DoubleDict) -> PredictionContext { // non-member
//  if merge_cache != nil {
//    let previous = merge_cache.Get(self.Hash(), self.Hash());
//    if previous != nil {
//      return previous.(PredictionContext)
//    }
//    previous = merge_cache.Get(self.Hash(), self.Hash())
//    if previous != nil {
//      return previous.(PredictionContext)
//    }
//  }
//  // merge sorted payloads a + b => M
//  let i = 0 // walks a;
//  let j = 0 // walks b;
//  let k = 0 // walks target M array;
//
//  let merged_return_states = make([]int, len(self.return_states) + len(self.return_states));
//  let merged_parents = make([]PredictionContext, len(self.return_states) + len(self.return_states));
//  // walk and merge to yield merged_parents, merged_return_states
//  for i < len(self.return_states) && j < len(self.return_states) {
//    let a_parent = self.parents[i];
//    let b_parent = self.parents[j];
//    if self.return_states[i] == self.return_states[j] {
//      // same payload (stack tops are equal), must yield merged singleton
//      let payload = self.return_states[i];
//      // $+$ = $
//      let both_dollars = payload == BasePredictionContextEmptyReturnState && a_parent == nil && b_parent == nil;
//      let ax_a_x = (aParent != nil && b_parent != nil && a_parent == b_parent) // ax+ax;
//      // ->
//      // ax
//      if both_dollars || ax_a_x {
//        merged_parents[k] = a_parent // choose left
//        merged_return_states[k] = payload
//      } else { // ax+ay -> a'[x,y]
//        let merged_parent = merge(aParent, b_parent, root_is_wildcard, merge_cache);
//        merged_parents[k] = merged_parent
//        merged_return_states[k] = payload
//      }
//      i++ // hop over left one as usual
//      j++ // but also Skip one in right side since we merge
//    } else if self.return_states[i] < self.return_states[j] { // copy a[i] to M
//      merged_parents[k] = a_parent
//      merged_return_states[k] = self.return_states[i]
//      i++
//    } else { // b > a, copy b[j] to M
//      merged_parents[k] = b_parent
//      merged_return_states[k] = self.return_states[j]
//      j++
//    }
//    k++
//  }
//  // copy over any payloads remaining in either array
//  if i < len(self.return_states) {
//    for let p = i; p < len(self.return_states); p++ {;
//      merged_parents[k] = self.parents[p]
//      merged_return_states[k] = self.return_states[p]
//      k++
//    }
//  } else {
//    for let p = j; p < len(self.return_states); p++ {;
//      merged_parents[k] = self.parents[p]
//      merged_return_states[k] = self.return_states[p]
//      k++
//    }
//  }
//  // trim merged if we combined a few that had same stack tops
//  if k < len(mergedParents) { // write index < last position trim
//    if k == 1 { // for just one merged element, return singleton top
//      let pc = SingletonBasePredictionContextCreate(mergedParents[0], merged_return_states[0]);
//      if merge_cache != nil {
//        merge_cache.set(self.Hash(), self.Hash(), pc)
//      }
//      return pc
//    }
//    merged_parents = merged_parents[0:k]
//    merged_return_states = merged_return_states[0:k]
//  }
//
//  let M = NewArrayPredictionContext(mergedParents, merged_return_states);
//
//  // if we created same array as a or b, return that instead
//  // TODO: track whether this is possible above during merge sort for speed
//  if M == a {
//    if merge_cache != nil {
//      merge_cache.set(self.Hash(), self.Hash(), a)
//    }
//    return a
//  }
//  if M == b {
//    if merge_cache != nil {
//      merge_cache.set(self.Hash(), self.Hash(), b)
//    }
//    return b
//  }
//  combine_common_parents(mergedParents)
//
//  if merge_cache != nil {
//    merge_cache.set(self.Hash(), self.Hash(), M)
//  }
//  return M
//}
//
////
//// Make pass over all <em>M</em> {@code parents} merge any {@code equals()}
//// ones.
//// /
//fn combine_common_parents(parents []PredictionContext) { // non-member
//  let unique_parents = make(map[PredictionContext]PredictionContext);
//
//  for let p = 0; p < len(parents); p++ {;
//    let parent = parents[p];
//    if unique_parents[parent] == nil {
//      unique_parents[parent] = parent
//    }
//  }
//  for let q = 0; q < len(parents); q++ {;
//    parents[q] = unique_parents[parents[q]]
//  }
//}
//
//fn cached_base_prediction_context(context: PredictionContext, context_cache *PredictionContextCache, visited map[PredictionContext]PredictionContext) -> PredictionContext { // non-member
//
//  if context.is_empty() {
//    return context
//  }
//  let existing = visited[context];
//  if existing != nil {
//    return existing
//  }
//  existing = context_cache.Get(context)
//  if existing != nil {
//    visited[context] = existing
//    return existing
//  }
//  let changed = false;
//  let parents = make([]PredictionContext, context.length());
//  for let i = 0; i < len(parents); i++ {;
//    let parent = cached_base_prediction_context(context.parent(i), context_cache, visited);
//    if changed || parent != context.parent(i) {
//      if !changed {
//        parents = make([]PredictionContext, context.length())
//        for let j = 0; j < context.length(); j++ {;
//          parents[j] = context.parent(j)
//        }
//        changed = true
//      }
//      parents[i] = parent
//    }
//  }
//  if !changed {
//    context_cache.add(context)
//    visited[context] = context
//    return context
//  }
//  var updated PredictionContext
//  if len(parents) == 0 {
//    updated = BasePredictionContextEMPTY
//  } else if len(parents) == 1 {
//    updated = SingletonBasePredictionContextCreate(parents[0], context.return_state(0))
//  } else {
//    updated = NewArrayPredictionContext(parents, context.(*ArrayPredictionContext).return_states())
//  }
//  context_cache.add(updated)
//  visited[updated] = updated
//  visited[context] = updated
//
//  return updated
//}
